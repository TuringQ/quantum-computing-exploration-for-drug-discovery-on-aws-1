{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2fe146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\py379\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:rdkit:Enabling RDKit 2022.03.5 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "# from utility.RetroParser import RetroData\n",
    "from utility.RetroGateModel import RetroRLModel\n",
    "from utility.RetroRLAgent import RetroRLAgent\n",
    "# from utility.ResultProcess import ResultParser\n",
    "from utility.DataPrepare import Prepare\n",
    "from utility.BruteForceSearch import expansion, Product, Reaction\n",
    "import time\n",
    "import numpy as np\n",
    "# # Use Braket SDK Cost Tracking to estimate the cost to run this example\n",
    "# from braket.tracking import Tracker\n",
    "# t = Tracker().start()\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e057ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd22750d-573b-4345-958d-ad6bfff053e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo list\n",
    "# 1. ground truth 在 preapre data 处理，保存成文件: true_reactions.npy; 在post process时，加载该文件（smiles string索引）\n",
    "# 2. prepare data 如果已经有文件，则跳过处理数据，不用raise exception\n",
    "# 3. interface\n",
    "#  3.1 （smiles_image.py) input：product smiles string， output：图片名字/位置\n",
    "#     function: 通过smiles索引图片\n",
    "#  3.2 step 4: (retro_inference.py) input：product smiles string，method output：逆合成路径+ground truth+score\n",
    "#     function：模型推理\n",
    "#  3.3 step 1+2+3 (retro_train.py) input: dataset, method, param output: train_job_id\n",
    "#     fucntion: 模型训练\n",
    "#     method:['rl-local', 'qrl-local', 'qrl-sv1', 'qrl-aspen']   \n",
    "#     !!!量子和经典retrol_agent， 通过method来判断choose reaction的具体操作\n",
    "#     !!!需要增加接口返回模型的参数大小（不同method下模型的参数量大小）\n",
    "#. 3.4 (get_job_status.py) input: train_job_id  output: job_status\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6b938",
   "metadata": {},
   "source": [
    "# Step 1: Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b418f",
   "metadata": {},
   "source": [
    "In this part, we load the retrosynthesis prediction data for experiment.\n",
    "The [USPTO-50K](https://tdcommons.ai/generation_tasks/retrosyn/#uspto-50k) was \n",
    "put in the repository. We assign the relative \n",
    "path to **raw_path**.\n",
    "The **s3_bucket** and **prefix** are used to store the \n",
    "results. We can use the one created with the \n",
    "cloudformation for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0df18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:parse xlsx file!\n",
      "INFO:root:There are at most 4 reactants in one reaction!\n",
      "INFO:root:Start picking dataset.\n",
      "  1%|█                                                                           | 715/50037 [01:39<1:54:09,  7.20it/s]"
     ]
    }
   ],
   "source": [
    "# input: predata_uspto-50k.xlsx\n",
    "# output: file1.npy,file2.npy\n",
    "raw_path = './uspto50k.xlsx'\n",
    "prepare = Prepare(raw_path)\n",
    "prepare.generate_files()  # \n",
    "prepare.generate_ground_truth()\n",
    "ground_truth = np.load(prepare.path+'ground_truth.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac41cba-76f1-49e5-ab1a-b1cdc8c86155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "子目录或文件 data 已经存在。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已复制         1 个文件。\n",
      "已复制         1 个文件。\n",
      "已复制         1 个文件。\n",
      "已复制         1 个文件。\n",
      "已复制         1 个文件。\n",
      "已复制         1 个文件。\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "!mkdir $data_path\n",
    "# !cp buyable.npy $data_path\n",
    "# !cp deadend.npy $data_path\n",
    "# !cp reactions_dictionary.npy $data_path\n",
    "# !cp smiles_dictionary.npy $data_path\n",
    "# !cp target_product.npy $data_path\n",
    "# !cp ground_truth.npy $data_path\n",
    "\n",
    "# windows\n",
    "!copy buyable.npy $data_path\n",
    "!copy deadend.npy $data_path\n",
    "!copy reactions_dictionary.npy $data_path\n",
    "!copy smiles_dictionary.npy $data_path\n",
    "!copy target_product.npy $data_path\n",
    "!copy ground_truth.npy $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431116a",
   "metadata": {},
   "source": [
    "# Step 2: Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f8310",
   "metadata": {},
   "source": [
    "In this part, we build the circuit model for retrosynthetic planning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c4c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial reinforcement learning for retrosynthetic-planning\n",
      "INFO:root:initial quantum reinforcement learning for retrosynthetic-planning\n"
     ]
    }
   ],
   "source": [
    "# initial the QMUQUBO object\n",
    "init_param = {}\n",
    "method = ['retro-rl', 'retro-qrl']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'retro-rl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['inputsize', 'middlesize', 'outputsize']\n",
    "    elif mt == 'retro-qrl':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['param'] = ['n_qubits', 'device', 'framework', 'shots']\n",
    "    \n",
    "retro_rl_model = RetroRLModel(data=None, method=method, **init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ea6e07-8dc2-4a44-bb18-285f6b576fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Construct model for inputsize:256,middlesize:512,outputsize:1 0.0034541726112365724 min\n"
     ]
    }
   ],
   "source": [
    "model_param={}\n",
    "method = 'retro-rl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['inputsize'] = [256]\n",
    "model_param[method]['middlesize'] = [512]\n",
    "model_param[method]['outputsize'] = [1]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa1f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Construct model for n_qubits:8,device:local,framework:pennylane 0.0005147377649943034 min\n",
      "INFO:root:Construct model for n_qubits:8,device:sv1,framework:pennylane 1.3736883799235026e-05 min\n",
      "INFO:root:Construct model for n_qubits:8,device:aspen-m2,framework:pennylane 0.0 min\n"
     ]
    }
   ],
   "source": [
    "model_param={}\n",
    "method = 'retro-qrl'\n",
    "model_param[method] = {}\n",
    "model_param[method]['n_qubits'] = [8]\n",
    "model_param[method]['device'] = ['local', 'sv1', 'aspen-m2']\n",
    "model_param[method]['framework'] = ['pennylane']\n",
    "model_param[method]['shots'] = [100]\n",
    "\n",
    "retro_rl_model.build_model(**model_param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9624b3f",
   "metadata": {},
   "source": [
    "We can use the following method to check the properties of \n",
    "model. This way, we can build many models conveniently. \n",
    "After that, we save the model and update the value of \n",
    "**model_path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431a9c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:method: retro-rl\n",
      "INFO:root:param: inputsize, value {256}\n",
      "INFO:root:param: middlesize, value {512}\n",
      "INFO:root:param: outputsize, value {1}\n",
      "INFO:root:method: retro-qrl\n",
      "INFO:root:param: n_qubits, value {8}\n",
      "INFO:root:param: device, value {'local', 'sv1', 'aspen-m2'}\n",
      "INFO:root:param: framework, value {'pennylane'}\n",
      "INFO:root:param: shots, value {100}\n"
     ]
    }
   ],
   "source": [
    "# describe the model parameters\n",
    "model_info = retro_rl_model.describe_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfdc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finish save retrorl_model_latest.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have built the nn model for RL and saved it as .\\retrorl_model_latest.pickle\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = retro_rl_model.save(\"latest\")\n",
    "\n",
    "print(f\"You have built the nn model for RL and saved it as {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b54a25-9ef1-4e2c-a591-def2a1322db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已复制         1 个文件。\n"
     ]
    }
   ],
   "source": [
    "# !cp $model_path $data_path\n",
    "\n",
    "# windows\n",
    "!copy $model_path $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42eb0f",
   "metadata": {},
   "source": [
    "# Step 3: Learn Retrosynthetic Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3febaf",
   "metadata": {},
   "source": [
    "In this part, we use cpu to run classical model for retrosynthetic planning \n",
    "and simulators/NISQ devices to run quantum model for retrosysnthetic planning.\n",
    "At first, we load the model file using **QMUQUBO** object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af955bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "inputsize = 256\n",
    "middlesize = 512\n",
    "outputsize = 1\n",
    "\n",
    "model_name = \"{}_{}_{}\".format(inputsize, middlesize, outputsize)\n",
    "method = \"retro-rl\"\n",
    "\n",
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84aa755a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:method: retro-rl\n",
      "INFO:root:param: inputsize, value {256}\n",
      "INFO:root:param: middlesize, value {512}\n",
      "INFO:root:param: outputsize, value {1}\n",
      "INFO:root:method: retro-qrl\n",
      "INFO:root:param: n_qubits, value {8}\n",
      "INFO:root:param: device, value {'local', 'sv1', 'aspen-m2'}\n",
      "INFO:root:param: framework, value {'pennylane'}\n",
      "INFO:root:param: shots, value {100}\n",
      "INFO:root:load data...\n",
      "INFO:root:model is {'model_name': '256_512_1', 'version': '1666666402', 'nn_model': Model(\n",
      "  (relu): ReLU()\n",
      "  (value_fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (value_fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('episode', 1)\n",
      "('episode', 2)\n",
      "('episode', 3)\n",
      "('episode', 4)\n",
      "('episode', 5)\n",
      "('episode', 6)\n",
      "('episode', 7)\n",
      "('episode', 8)\n",
      "('episode', 9)\n",
      "('episode', 10)\n",
      "('episode', 11)\n",
      "('episode', 12)\n",
      "('episode', 13)\n",
      "('episode', 14)\n",
      "('episode', 15)\n",
      "('episode', 16)\n",
      "('episode', 17)\n",
      "('episode', 18)\n",
      "('episode', 19)\n",
      "('episode', 20)\n",
      "epsiode 20 training...\n",
      "finish epoch 0 for 0.007039034366607666 minutes\n",
      "finish epoch 1 for 5.002419153849284e-05 minutes\n",
      "finish epoch 2 for 1.6987323760986328e-05 minutes\n",
      "finish epoch 3 for 1.633167266845703e-05 minutes\n",
      "finish epoch 4 for 1.6681353251139323e-05 minutes\n",
      "finish epoch 5 for 0.0 minutes\n",
      "finish epoch 6 for 3.3644835154215497e-05 minutes\n",
      "finish epoch 7 for 1.5795230865478516e-05 minutes\n",
      "finish epoch 8 for 3.344217936197917e-05 minutes\n",
      "finish epoch 9 for 1.6542275746663413e-05 minutes\n",
      "finish epoch 10 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 11 for 3.3406416575113934e-05 minutes\n",
      "finish epoch 12 for 1.6578038533528645e-05 minutes\n",
      "finish epoch 13 for 1.666545867919922e-05 minutes\n",
      "finish epoch 14 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 15 for 0.0 minutes\n",
      "finish epoch 16 for 1.66932741800944e-05 minutes\n",
      "finish epoch 17 for 1.665353775024414e-05 minutes\n",
      "finish epoch 18 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 19 for 0.0 minutes\n",
      "('episode', 21)\n",
      "('episode', 22)\n",
      "('episode', 23)\n",
      "('episode', 24)\n",
      "('episode', 25)\n",
      "('episode', 26)\n",
      "('episode', 27)\n",
      "('episode', 28)\n",
      "('episode', 29)\n",
      "('episode', 30)\n",
      "('episode', 31)\n",
      "('episode', 32)\n",
      "('episode', 33)\n",
      "('episode', 34)\n",
      "('episode', 35)\n",
      "('episode', 36)\n",
      "('episode', 37)\n",
      "('episode', 38)\n",
      "('episode', 39)\n",
      "('episode', 40)\n",
      "epsiode 40 training...\n",
      "finish epoch 0 for 3.332694371541341e-05 minutes\n",
      "finish epoch 1 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 2 for 1.665353775024414e-05 minutes\n",
      "finish epoch 3 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 4 for 1.666545867919922e-05 minutes\n",
      "finish epoch 5 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 6 for 3.345807393391927e-05 minutes\n",
      "finish epoch 7 for 1.666545867919922e-05 minutes\n",
      "finish epoch 8 for 1.654624938964844e-05 minutes\n",
      "finish epoch 9 for 1.6697247823079427e-05 minutes\n",
      "finish epoch 10 for 3.332694371541341e-05 minutes\n",
      "finish epoch 11 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 12 for 3.336270650227865e-05 minutes\n",
      "finish epoch 13 for 1.6629695892333984e-05 minutes\n",
      "finish epoch 14 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 15 for 1.6677379608154298e-05 minutes\n",
      "finish epoch 16 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 17 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 18 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 19 for 3.3342838287353514e-05 minutes\n",
      "('episode', 41)\n",
      "('episode', 42)\n",
      "('episode', 43)\n",
      "('episode', 44)\n",
      "('episode', 45)\n",
      "('episode', 46)\n",
      "('episode', 47)\n",
      "('episode', 48)\n",
      "('episode', 49)\n",
      "('episode', 50)\n",
      "('episode', 51)\n",
      "('episode', 52)\n",
      "('episode', 53)\n",
      "('episode', 54)\n",
      "('episode', 55)\n",
      "('episode', 56)\n",
      "('episode', 57)\n",
      "('episode', 58)\n",
      "('episode', 59)\n",
      "('episode', 60)\n",
      "epsiode 60 training...\n",
      "finish epoch 0 for 3.330707550048828e-05 minutes\n",
      "finish epoch 1 for 3.333091735839844e-05 minutes\n",
      "finish epoch 2 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 3 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 4 for 3.332297007242839e-05 minutes\n",
      "finish epoch 5 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 6 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 7 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 8 for 1.665353775024414e-05 minutes\n",
      "finish epoch 9 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 10 for 1.668532689412435e-05 minutes\n",
      "finish epoch 11 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 12 for 1.668532689412435e-05 minutes\n",
      "finish epoch 13 for 1.6641616821289062e-05 minutes\n",
      "finish epoch 14 for 3.332694371541341e-05 minutes\n",
      "finish epoch 15 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 16 for 1.668532689412435e-05 minutes\n",
      "finish epoch 17 for 1.665353775024414e-05 minutes\n",
      "finish epoch 18 for 1.6681353251139323e-05 minutes\n",
      "finish epoch 19 for 3.333091735839844e-05 minutes\n",
      "('episode', 61)\n",
      "('episode', 62)\n",
      "('episode', 63)\n",
      "('episode', 64)\n",
      "('episode', 65)\n",
      "('episode', 66)\n",
      "('episode', 67)\n",
      "('episode', 68)\n",
      "('episode', 69)\n",
      "('episode', 70)\n",
      "('episode', 71)\n",
      "('episode', 72)\n",
      "('episode', 73)\n",
      "('episode', 74)\n",
      "('episode', 75)\n",
      "('episode', 76)\n",
      "('episode', 77)\n",
      "('episode', 78)\n",
      "('episode', 79)\n",
      "('episode', 80)\n",
      "epsiode 80 training...\n",
      "finish epoch 0 for 3.32792599995931e-05 minutes\n",
      "finish epoch 1 for 1.666545867919922e-05 minutes\n",
      "finish epoch 2 for 1.666545867919922e-05 minutes\n",
      "finish epoch 3 for 1.666545867919922e-05 minutes\n",
      "finish epoch 4 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 5 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 6 for 1.6677379608154298e-05 minutes\n",
      "finish epoch 7 for 3.332694371541341e-05 minutes\n",
      "finish epoch 8 for 1.6677379608154298e-05 minutes\n",
      "finish epoch 9 for 1.6645590464274088e-05 minutes\n",
      "finish epoch 10 for 1.6681353251139323e-05 minutes\n",
      "finish epoch 11 for 1.665353775024414e-05 minutes\n",
      "finish epoch 12 for 1.666545867919922e-05 minutes\n",
      "finish epoch 13 for 1.6677379608154298e-05 minutes\n",
      "finish epoch 14 for 1.6661485036214194e-05 minutes\n",
      "finish epoch 15 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 16 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 17 for 1.672506332397461e-05 minutes\n",
      "finish epoch 18 for 3.3283233642578124e-05 minutes\n",
      "finish epoch 19 for 1.6661485036214194e-05 minutes\n",
      "('episode', 81)\n",
      "('episode', 82)\n",
      "('episode', 83)\n",
      "('episode', 84)\n",
      "('episode', 85)\n",
      "('episode', 86)\n",
      "('episode', 87)\n",
      "('episode', 88)\n",
      "('episode', 89)\n",
      "('episode', 90)\n",
      "('episode', 91)\n",
      "('episode', 92)\n",
      "('episode', 93)\n",
      "('episode', 94)\n",
      "('episode', 95)\n",
      "('episode', 96)\n",
      "('episode', 97)\n",
      "('episode', 98)\n",
      "('episode', 99)\n",
      "('episode', 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finish save agent256_512_1_latest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsiode 100 training...\n",
      "finish epoch 0 for 3.3354759216308595e-05 minutes\n",
      "finish epoch 1 for 1.6657511393229165e-05 minutes\n",
      "finish epoch 2 for 1.6681353251139323e-05 minutes\n",
      "finish epoch 3 for 1.665353775024414e-05 minutes\n",
      "finish epoch 4 for 1.6669432322184246e-05 minutes\n",
      "finish epoch 5 for 1.6681353251139323e-05 minutes\n",
      "finish epoch 6 for 1.6649564107259113e-05 minutes\n",
      "finish epoch 7 for 3.3354759216308595e-05 minutes\n",
      "finish epoch 8 for 1.6645590464274088e-05 minutes\n",
      "finish epoch 9 for 1.6689300537109375e-05 minutes\n",
      "finish epoch 10 for 1.665353775024414e-05 minutes\n",
      "finish epoch 11 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 12 for 3.331899642944336e-05 minutes\n",
      "finish epoch 13 for 1.6701221466064452e-05 minutes\n",
      "finish epoch 14 for 1.6641616821289062e-05 minutes\n",
      "finish epoch 15 for 1.6673405965169272e-05 minutes\n",
      "finish epoch 16 for 1.665353775024414e-05 minutes\n",
      "finish epoch 17 for 3.3354759216308595e-05 minutes\n",
      "finish epoch 18 for 1.6697247823079427e-05 minutes\n",
      "finish epoch 19 for 1.6609827677408855e-05 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('data\\\\256_512_1_latest', '256_512_1_latest')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# data_path = 'D:\\工作\\论文\\分子逆合成/retrosynthesis/data2\\data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_rl_model = RetroRLModel.load(model_path)\n",
    "model_info = retro_rl_model.describe_model()\n",
    "retro_model = retro_rl_model.get_model(method, model_name)\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game()\n",
    "retro_rl_agent.save(\"latest\", path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edad7abf-cdd6-4629-8bc7-8e3b4054b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./retrorl_model_latest.pickle'\n",
    "\n",
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'sv1'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baba9dfc-ca51-43a1-b7bf-9459f3459402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mode can be: \"local-instance\", \"local-job\", \"hybrid-job\"\n",
    "train_mode = \"hybrid-job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8537e938-942f-4357-92d8-95af3735de99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load data...\n",
      "INFO:root:model is None\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to run sv1 mode\n",
      "create job with arn arn:aws:braket:us-east-1:493904798517:job/retrorl-job-sv1-torch-1666666506\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# data_path = 'D:\\工作\\论文\\分子逆合成/retrosynthesis/data2\\data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f803eb8-3a13-4e6b-87f7-2882d8c3ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load data...\n",
      "INFO:root:model is None\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to run local mode\n",
      "create job with arn arn:aws:braket:us-east-1:493904798517:job/retrorl-job-local-torch-1666666543\n"
     ]
    }
   ],
   "source": [
    "# get the model you want to optimize\n",
    "n_qubits = 8\n",
    "device = 'local'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "data_path = 'data'\n",
    "# data_path = 'D:\\工作\\论文\\分子逆合成/retrosynthesis/data2\\data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4b5708-61f0-4427-863f-a3769faa984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load data...\n",
      "INFO:root:model is None\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to run aspen-m2 mode\n",
      "create job with arn arn:aws:braket:us-west-1:493904798517:job/retrorl-job-aspen-m2-torch-1666666552\n"
     ]
    }
   ],
   "source": [
    "# get the model you want to optimize\n",
    "# config your aws account in your ~/.aws/config\n",
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION']='us-west-1'\n",
    "\n",
    "n_qubits = 8\n",
    "device = 'aspen-m2'\n",
    "framework = 'pennylane'\n",
    "shots = 100\n",
    "\n",
    "model_name = \"{}_{}_{}_{}\".format(n_qubits, device, framework, shots)\n",
    "method = \"retro-qrl\"\n",
    "\n",
    "data_path = 'data'\n",
    "# data_path = 'D:\\工作\\论文\\分子逆合成/retrosynthesis/data2\\data'\n",
    "agent_param = {}\n",
    "agent_param[\"data_path\"] = data_path\n",
    "agent_param[\"train_mode\"] = train_mode\n",
    "agent_param[\"model_name\"] = model_name\n",
    "agent_param[\"model_path\"] = model_path\n",
    "\n",
    "retro_model = None\n",
    "if train_mode == \"local-instance\":\n",
    "    # get model\n",
    "    retro_rl_model = RetroRLModel.load(model_path)\n",
    "    model_info = retro_rl_model.describe_model()\n",
    "    retro_model = retro_rl_model.get_model(method, model_name)\n",
    "\n",
    "retro_rl_agent = RetroRLAgent(retro_model, method, **agent_param)\n",
    "retro_rl_agent.game_job()\n",
    "\n",
    "job_arn = retro_rl_agent.get_job_arn()\n",
    "print(f\"create job with arn {job_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80958946-4527-41f3-9b21-e13c77179a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CANCELLING'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retro_rl_agent.get_job().cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363515e",
   "metadata": {},
   "source": [
    "We can see the parameters of this model, with M equaling 1,2 or 3, D equaling 8, \n",
    "A equaling 300 and hubo_qubo_val equaling 200. \n",
    "Actually, we can contain multiple models in this file just \n",
    "by giving multiple values for one parameter when creating models.\n",
    "\n",
    "Actually, we can contain multiple models in this file just \n",
    "by giving multiple values for one parameter when creating models.\n",
    "Then, we need use **model_name** to get the model for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "246dd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_path = retro_rl_agent.save(\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcba0ff",
   "metadata": {},
   "source": [
    "# Step 4: PostProcess Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd3c040",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RetroRLAgent' object has no attribute 'NN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_65964\\159607665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mretro_rl_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpathway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlayer2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretro_rl_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(layer2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\retrosynthetic-planning-tmp\\utility\\RetroRLAgent.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mRetroRLAgent.RetroRLAgent.pathway\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\retrosynthetic-planning-tmp\\utility\\RetroRLAgent.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mRetroRLAgent.RetroRLAgent.choosereaction\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RetroRLAgent' object has no attribute 'NN'"
     ]
    }
   ],
   "source": [
    "target = 'COC(Cc1ccc2oc(Cc3nc(-c4ccccc4)oc3C)cc2c1)OC'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f58dad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'O=C(O)c1ccccn1', 'NCc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1', 'N#Cc1ccc(CO)cc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(NCc1ccc(CO)cc1)c1ccccn1', 'O=C(O)c1ccccn1', 'NCc1ccc(CO)cc1', 'N#Cc1ccc(C=O)cc1', 'N#Cc1ccc(CO)cc1'}\n",
      "The real_cost of Brute force: \n",
      "  3.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'O=C(NCc1ccc(CO)cc1)c1ccccn1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "634c442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path of retro_rl_agent: \n",
      "  {'O=C(Cl)c1ccccc1', 'c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'O=C(c1ccccc1)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'}\n",
      "The real_path of Brute force: \n",
      "  {'O=C(Cl)c1ccccc1', 'c1ccccc1', 'CCCCC(CC)COC(=O)CC#N', 'O=C(c1ccccc1)c1ccccc1', 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'}\n",
      "The real_cost of Brute force: \n",
      "  2.0\n",
      "Get the same path: True\n"
     ]
    }
   ],
   "source": [
    "target = 'CCCCC(CC)COC(=O)C(C#N)=C(c1ccccc1)c1ccccc1'\n",
    "retro_rl_agent.pathway(target)\n",
    "layer2 = retro_rl_agent.layer2\n",
    "# print(layer2)\n",
    "path = set()\n",
    "for i, j in layer2.items():\n",
    "    for k, l  in j.items():\n",
    "        path.add(l)\n",
    "print(f\"The path of retro_rl_agent: \\n \\\n",
    " {path}\")\n",
    "\n",
    "input_data_path = agent_param[\"data_path\"]\n",
    "ground_truth = np.load(input_data_path+'/ground_truth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "real_path = set(ground_truth[target]['path'])\n",
    "print(f\"The real_path of Brute force: \\n \\\n",
    " {real_path}\")\n",
    "real_cost = ground_truth[target]['cost']\n",
    "print(f\"The real_cost of Brute force: \\n \\\n",
    " {real_cost}\")\n",
    "print(f\"Get the same path: {path == real_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py379",
   "language": "python",
   "name": "py379"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
